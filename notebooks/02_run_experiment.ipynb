{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Phishing SMS : CoPhi @ SJTU\n",
        "**Author**: Napassorn LITCHIOWONG (Pleng/林艺文)\n",
        "pleng@u.nus.edu"
      ],
      "metadata": {
        "id": "oBhCCtZ-kE6c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phishing SMS : CoPhi @ SJTU\n",
        "**Author**: Napassorn LITCHIOWONG (Pleng/林艺文)\n",
        "pleng@u.nus.edu"
      ],
      "metadata": {
        "id": "JzF5l-TOlKxg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Edit the config path and output dir before running\n"
      ],
      "metadata": {
        "id": "23o72mHBlCJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFqk2lIAadDl",
        "outputId": "d4381ba5-bf02-43f0-ba64-cebf7c30f9b1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os, sys, json, yaml, importlib, traceback, glob, shutil, subprocess, getpass\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "REPO_DIR = \"/content/drive/MyDrive/sms-baselines\"\n",
        "MAX_RUNS_PER_BASELINE = 5\n",
        "OVERWRITE_EXISTING = True\n",
        "CHECKPOINT_EVERY_RUN = True\n",
        "PUSH_EVERY_BASELINE = True\n",
        "\n",
        "if not os.path.exists(REPO_DIR):\n",
        "    raise FileNotFoundError(f\"Repository not found at {REPO_DIR}\")\n",
        "\n",
        "sys.path.insert(0, REPO_DIR)\n",
        "sys.path.insert(0, os.path.join(REPO_DIR, \"src\"))\n",
        "from models.shared import set_seed\n",
        "\n",
        "train_csv = os.path.join(REPO_DIR, \"data\", \"splits\", \"train.csv\")\n",
        "test_csv = os.path.join(REPO_DIR, \"data\", \"splits\", \"test.csv\")\n",
        "train_df = pd.read_csv(train_csv)\n",
        "test_df = pd.read_csv(test_csv)\n",
        "\n",
        "config_paths = sorted(glob.glob(os.path.join(REPO_DIR, \"configs\", \"bl_*.yaml\")))\n",
        "BASE_EXP_DIR = os.path.join(REPO_DIR, \"experiments\")\n",
        "os.makedirs(BASE_EXP_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Experiments will be saved to: {BASE_EXP_DIR}\")\n",
        "print(f\"Working directory: {os.getcwd()}\")\n",
        "print(f\"Repository directory: {REPO_DIR}\")\n",
        "print(f\"Checkpoint mode: Save after each run = {CHECKPOINT_EVERY_RUN}\")\n",
        "print(f\"Push mode: Push after each baseline = {PUSH_EVERY_BASELINE}\")\n",
        "\n",
        "def check_baseline_complete(baseline_dir, expected_runs):\n",
        "    if not os.path.exists(baseline_dir):\n",
        "        return False\n",
        "\n",
        "    summary_csv = os.path.join(baseline_dir, \"summary.csv\")\n",
        "    if os.path.exists(summary_csv):\n",
        "        try:\n",
        "            df = pd.read_csv(summary_csv)\n",
        "            successful_runs = df[df['accuracy'].notna()]\n",
        "            return len(successful_runs) >= expected_runs\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    run_dirs = [item for item in os.listdir(baseline_dir)\n",
        "                if os.path.isdir(os.path.join(baseline_dir, item))]\n",
        "\n",
        "    successful_runs = 0\n",
        "    for run_dir in run_dirs:\n",
        "        results_path = os.path.join(baseline_dir, run_dir, \"results.json\")\n",
        "        if os.path.exists(results_path):\n",
        "            try:\n",
        "                with open(results_path) as f:\n",
        "                    results = json.load(f)\n",
        "                if results.get(\"accuracy\") is not None:\n",
        "                    successful_runs += 1\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    return successful_runs >= expected_runs\n",
        "\n",
        "def cleanup_old_runs(baseline_dir, max_runs=MAX_RUNS_PER_BASELINE):\n",
        "    if not os.path.exists(baseline_dir):\n",
        "        return\n",
        "    run_dirs = [(item, os.path.join(baseline_dir, item), os.path.getmtime(os.path.join(baseline_dir, item)))\n",
        "                for item in os.listdir(baseline_dir)\n",
        "                if os.path.isdir(os.path.join(baseline_dir, item))]\n",
        "    run_dirs.sort(key=lambda x: x[2], reverse=True)\n",
        "    for run_name, run_path, _ in run_dirs[max_runs:]:\n",
        "        shutil.rmtree(run_path, ignore_errors=True)\n",
        "\n",
        "def get_run_dir(baseline_dir, baseline_id, seed):\n",
        "    os.makedirs(baseline_dir, exist_ok=True)\n",
        "    if OVERWRITE_EXISTING:\n",
        "        for item in os.listdir(baseline_dir):\n",
        "            item_path = os.path.join(baseline_dir, item)\n",
        "            if os.path.isdir(item_path):\n",
        "                meta_path = os.path.join(item_path, \"run_meta.json\")\n",
        "                if os.path.exists(meta_path):\n",
        "                    try:\n",
        "                        with open(meta_path) as f:\n",
        "                            meta = json.load(f)\n",
        "                        if meta.get(\"seed\") == seed:\n",
        "                            return item_path\n",
        "                    except:\n",
        "                        pass\n",
        "    now = datetime.utcnow().strftime(\"%Y%m%dT%H%M%SZ\")\n",
        "    run_id = f\"{baseline_id}_seed{seed}_{now}\"\n",
        "    run_dir = os.path.join(baseline_dir, run_id)\n",
        "    os.makedirs(run_dir, exist_ok=True)\n",
        "    return run_dir\n",
        "\n",
        "auth_setup_done = False\n",
        "def setup_github_auth():\n",
        "    global auth_setup_done\n",
        "    if auth_setup_done:\n",
        "        return True\n",
        "\n",
        "    print(\"Setting up GitHub authentication...\")\n",
        "    token = getpass.getpass(\"Enter your GitHub Personal Access Token: \")\n",
        "    username = \"iamdiluxedbutcooler\"\n",
        "    remote_url = f\"https://{username}:{token}@github.com/{username}/sms-baselines.git\"\n",
        "    try:\n",
        "        os.chdir(REPO_DIR)\n",
        "        subprocess.run([\"git\", \"remote\", \"remove\", \"origin\"], capture_output=True)\n",
        "        subprocess.run([\"git\", \"remote\", \"add\", \"origin\", remote_url], check=True)\n",
        "        print(\"GitHub authentication configured successfully!\")\n",
        "        auth_setup_done = True\n",
        "        return True\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Failed to configure GitHub auth: {e}\")\n",
        "        return False\n",
        "\n",
        "def commit_and_push_checkpoint(message_suffix=\"\"):\n",
        "    try:\n",
        "        os.chdir(REPO_DIR)\n",
        "        result = subprocess.run([\"git\", \"status\", \"--porcelain\"], capture_output=True, text=True)\n",
        "        if not result.stdout.strip():\n",
        "            print(\"No changes to commit\")\n",
        "            return True\n",
        "\n",
        "        subprocess.run([\"git\", \"add\", \"experiments/\"], check=True)\n",
        "        subprocess.run([\"git\", \"add\", \"src/\"], check=True)\n",
        "        subprocess.run([\"git\", \"add\", \"configs/\"], check=True)\n",
        "\n",
        "        result = subprocess.run([\"git\", \"diff\", \"--cached\", \"--name-only\"], capture_output=True, text=True)\n",
        "        if not result.stdout.strip():\n",
        "            print(\"No changes staged for commit\")\n",
        "            return True\n",
        "\n",
        "        timestamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        commit_msg = f\"Checkpoint {timestamp}{message_suffix}\"\n",
        "        subprocess.run([\"git\", \"commit\", \"-m\", commit_msg], check=True)\n",
        "        subprocess.run([\"git\", \"push\", \"origin\", \"main\"], check=True)\n",
        "        print(f\"Checkpoint pushed at {timestamp}\")\n",
        "        return True\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Checkpoint push failed: {e}\")\n",
        "        return False\n",
        "\n",
        "def save_progress_state(baseline_id, completed_runs, all_results):\n",
        "    progress_file = os.path.join(BASE_EXP_DIR, \"training_progress.json\")\n",
        "    progress_data = {\n",
        "        \"last_baseline\": baseline_id,\n",
        "        \"completed_runs\": completed_runs,\n",
        "        \"timestamp\": datetime.utcnow().isoformat(),\n",
        "        \"total_results\": len(all_results)\n",
        "    }\n",
        "    with open(progress_file, \"w\") as f:\n",
        "        json.dump(progress_data, f, indent=2)\n",
        "\n",
        "def load_progress_state():\n",
        "    progress_file = os.path.join(BASE_EXP_DIR, \"training_progress.json\")\n",
        "    if os.path.exists(progress_file):\n",
        "        try:\n",
        "            with open(progress_file) as f:\n",
        "                return json.load(f)\n",
        "        except:\n",
        "            pass\n",
        "    return {}\n",
        "\n",
        "progress_state = load_progress_state()\n",
        "if progress_state:\n",
        "    print(f\"Previous session found: {progress_state.get('last_baseline')} - {progress_state.get('completed_runs')} runs\")\n",
        "\n",
        "all_results = []\n",
        "skipped_baselines = []\n",
        "github_auth_configured = False\n",
        "\n",
        "for cfg_idx, cfg_path in enumerate(config_paths):\n",
        "    print(f\"\\nProcessing ({cfg_idx+1}/{len(config_paths)}): {os.path.basename(cfg_path)}\")\n",
        "    with open(cfg_path) as f:\n",
        "        config = yaml.safe_load(f)\n",
        "    baseline_id = config.get(\"baseline_id\", os.path.splitext(os.path.basename(cfg_path))[0])\n",
        "    module_path = config.get(\"module\")\n",
        "    if not module_path:\n",
        "        print(f\"  No module specified, skipping\")\n",
        "        continue\n",
        "\n",
        "    baseline_dir = os.path.join(BASE_EXP_DIR, baseline_id)\n",
        "    repeats = config.get(\"training\", {}).get(\"repeats_for_variance\", 1)\n",
        "\n",
        "    if check_baseline_complete(baseline_dir, repeats):\n",
        "        print(f\"  Baseline {baseline_id} already complete ({repeats} runs), skipping\")\n",
        "        skipped_baselines.append(baseline_id)\n",
        "\n",
        "        summary_csv = os.path.join(baseline_dir, \"summary.csv\")\n",
        "        if os.path.exists(summary_csv):\n",
        "            try:\n",
        "                df = pd.read_csv(summary_csv)\n",
        "                for _, row in df.iterrows():\n",
        "                    if pd.notna(row.get('accuracy')):\n",
        "                        all_results.append({\n",
        "                            \"baseline\": baseline_id,\n",
        "                            \"seed\": row.get(\"seed\"),\n",
        "                            \"accuracy\": row.get(\"accuracy\"),\n",
        "                            \"outdir\": row.get(\"outdir\")\n",
        "                        })\n",
        "            except:\n",
        "                pass\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        module = importlib.import_module(module_path)\n",
        "    except Exception as e:\n",
        "        print(f\"  Import failed for {module_path}: {e}\")\n",
        "        continue\n",
        "\n",
        "    baseline_completed_runs = 0\n",
        "    seed_base = config.get(\"training\", {}).get(\"seed_base\", 42)\n",
        "\n",
        "    for i in range(repeats):\n",
        "        seed = seed_base + i\n",
        "        set_seed(seed)\n",
        "        print(f\"  Running seed {seed} ({i+1}/{repeats})...\")\n",
        "        outdir = get_run_dir(baseline_dir, baseline_id, seed)\n",
        "        run_meta = {\"baseline\": baseline_id, \"seed\": seed, \"timestamp\": datetime.utcnow().isoformat()}\n",
        "        with open(os.path.join(outdir, \"run_meta.json\"), \"w\") as f:\n",
        "            json.dump(run_meta, f, indent=2)\n",
        "\n",
        "        try:\n",
        "            entry_fn = None\n",
        "            expected = f\"run_{baseline_id}\"\n",
        "            if hasattr(module, expected):\n",
        "                entry_fn = getattr(module, expected)\n",
        "            else:\n",
        "                for name in dir(module):\n",
        "                    if name.startswith(\"run_\") and callable(getattr(module, name)):\n",
        "                        entry_fn = getattr(module, name)\n",
        "                        break\n",
        "            if not entry_fn:\n",
        "                raise Exception(f\"No run function found in {module_path}\")\n",
        "\n",
        "            results = entry_fn(\n",
        "                train_df[\"text\"].astype(str).tolist(),\n",
        "                train_df[\"label\"].astype(str).tolist(),\n",
        "                test_df[\"text\"].astype(str).tolist(),\n",
        "                test_df[\"label\"].astype(str).tolist(),\n",
        "                outdir, seed, config\n",
        "            )\n",
        "            accuracy = results.get(\"accuracy\")\n",
        "            print(f\"    Accuracy: {accuracy}\")\n",
        "            all_results.append({\n",
        "                \"baseline\": baseline_id,\n",
        "                \"seed\": seed,\n",
        "                \"accuracy\": accuracy,\n",
        "                \"outdir\": outdir\n",
        "            })\n",
        "            baseline_completed_runs += 1\n",
        "\n",
        "            if CHECKPOINT_EVERY_RUN:\n",
        "                baseline_results = [r for r in all_results if r[\"baseline\"] == baseline_id]\n",
        "                if baseline_results:\n",
        "                    pd.DataFrame(baseline_results).to_csv(os.path.join(baseline_dir, \"summary.csv\"), index=False)\n",
        "\n",
        "                save_progress_state(baseline_id, baseline_completed_runs, all_results)\n",
        "\n",
        "                if not github_auth_configured:\n",
        "                    github_auth_configured = setup_github_auth()\n",
        "\n",
        "                if github_auth_configured:\n",
        "                    commit_and_push_checkpoint(f\" - {baseline_id} run {i+1}/{repeats}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"    Error: {e}\")\n",
        "            with open(os.path.join(outdir, \"error.txt\"), \"w\") as f:\n",
        "                f.write(traceback.format_exc())\n",
        "            all_results.append({\n",
        "                \"baseline\": baseline_id,\n",
        "                \"seed\": seed,\n",
        "                \"accuracy\": None,\n",
        "                \"outdir\": outdir,\n",
        "                \"error\": str(e)\n",
        "            })\n",
        "\n",
        "    cleanup_old_runs(baseline_dir)\n",
        "    baseline_results = [r for r in all_results if r[\"baseline\"] == baseline_id]\n",
        "    if baseline_results:\n",
        "        pd.DataFrame(baseline_results).to_csv(os.path.join(baseline_dir, \"summary.csv\"), index=False)\n",
        "\n",
        "    if PUSH_EVERY_BASELINE and github_auth_configured:\n",
        "        commit_and_push_checkpoint(f\" - {baseline_id} completed\")\n",
        "        print(f\"  Baseline {baseline_id} results pushed to GitHub\")\n",
        "\n",
        "    save_progress_state(baseline_id, baseline_completed_runs, all_results)\n",
        "\n",
        "if all_results:\n",
        "    pd.DataFrame(all_results).to_csv(os.path.join(BASE_EXP_DIR, \"experiments_summary.csv\"), index=False)\n",
        "\n",
        "print(f\"\\nCompleted! Results in {BASE_EXP_DIR}\")\n",
        "print(f\"Each baseline keeps max {MAX_RUNS_PER_BASELINE} runs\")\n",
        "\n",
        "if skipped_baselines:\n",
        "    print(f\"\\nSkipped baselines (already complete): {', '.join(skipped_baselines)}\")\n",
        "\n",
        "print(f\"\\nExperiments directory contents:\")\n",
        "if os.path.exists(BASE_EXP_DIR):\n",
        "    for item in os.listdir(BASE_EXP_DIR):\n",
        "        item_path = os.path.join(BASE_EXP_DIR, item)\n",
        "        if os.path.isdir(item_path):\n",
        "            run_count = len([x for x in os.listdir(item_path) if os.path.isdir(os.path.join(item_path, x))])\n",
        "            status = \"(SKIPPED)\" if item in skipped_baselines else \"(TRAINED)\"\n",
        "            print(f\"  {item}: {run_count} runs {status}\")\n",
        "        else:\n",
        "            print(f\"  {item}: file\")\n",
        "\n",
        "if not github_auth_configured:\n",
        "    print(\"\\nSetting up final GitHub push...\")\n",
        "    if setup_github_auth():\n",
        "        commit_and_push_checkpoint(\" - Final results\")\n",
        "        print(\"Final results pushed to GitHub!\")\n",
        "    else:\n",
        "        print(\"GitHub authentication failed. Results saved locally only.\")\n",
        "\n",
        "progress_file = os.path.join(BASE_EXP_DIR, \"training_progress.json\")\n",
        "if os.path.exists(progress_file):\n",
        "    os.remove(progress_file)\n",
        "    print(\"Training progress file cleaned up.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXjRTbVoD33u",
        "outputId": "7bb2fac3-f3d5-4326-8ed8-bd5c6887ba26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Experiments will be saved to: /content/drive/MyDrive/sms-baselines/experiments\n",
            "Working directory: /content\n",
            "Repository directory: /content/drive/MyDrive/sms-baselines\n",
            "Checkpoint mode: Save after each run = True\n",
            "Push mode: Push after each baseline = True\n",
            "\n",
            "Processing (1/3): bl_nlp_01.yaml\n",
            "  Baseline bl_nlp_01 already complete (5 runs), skipping\n",
            "\n",
            "Processing (2/3): bl_nlp_02.yaml\n",
            "  Baseline bl_nlp_02 already complete (5 runs), skipping\n",
            "\n",
            "Processing (3/3): bl_nn_01.yaml\n",
            "  Running seed 42 (1/5)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3288849877.py:221: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  run_meta = {\"baseline\": baseline_id, \"seed\": seed, \"timestamp\": datetime.utcnow().isoformat()}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original train labels: {'smishing', 'ham', 'spam'}\n",
            "Original test labels: {'smishing', 'ham', 'spam'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model...\n",
            "Epoch 1/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 291ms/step - accuracy: 0.7995 - loss: 0.5459 - val_accuracy: 0.6799 - val_loss: 0.4328\n",
            "Epoch 2/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 287ms/step - accuracy: 0.7555 - loss: 0.3958 - val_accuracy: 0.6695 - val_loss: 0.4221\n",
            "Epoch 3/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 293ms/step - accuracy: 0.7459 - loss: 0.3813 - val_accuracy: 0.7050 - val_loss: 0.3964\n",
            "Epoch 4/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 286ms/step - accuracy: 0.7546 - loss: 0.3702 - val_accuracy: 0.7385 - val_loss: 0.3709\n",
            "Epoch 5/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 282ms/step - accuracy: 0.7603 - loss: 0.3533 - val_accuracy: 0.7741 - val_loss: 0.3235\n",
            "Epoch 6/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 281ms/step - accuracy: 0.7821 - loss: 0.3131 - val_accuracy: 0.8347 - val_loss: 0.2622\n",
            "Epoch 7/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 283ms/step - accuracy: 0.8045 - loss: 0.2470 - val_accuracy: 0.7573 - val_loss: 0.1029\n",
            "Epoch 8/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 285ms/step - accuracy: 0.8133 - loss: 0.1793 - val_accuracy: 0.7510 - val_loss: 0.0390\n",
            "Epoch 9/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 283ms/step - accuracy: 0.8313 - loss: 0.1612 - val_accuracy: 0.8515 - val_loss: -0.1107\n",
            "Epoch 10/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 284ms/step - accuracy: 0.8334 - loss: 0.0408 - val_accuracy: 0.8243 - val_loss: -0.0914\n",
            "Epoch 11/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 282ms/step - accuracy: 0.8278 - loss: 0.0184 - val_accuracy: 0.8682 - val_loss: 0.2018\n",
            "Epoch 12/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 285ms/step - accuracy: 0.8373 - loss: -0.0921 - val_accuracy: 0.7469 - val_loss: -0.2709\n",
            "Epoch 13/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 282ms/step - accuracy: 0.8367 - loss: -0.1476 - val_accuracy: 0.7008 - val_loss: -0.1548\n",
            "Epoch 14/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 284ms/step - accuracy: 0.8096 - loss: -0.0988 - val_accuracy: 0.8556 - val_loss: -0.6857\n",
            "Epoch 15/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 284ms/step - accuracy: 0.8360 - loss: -0.2838 - val_accuracy: 0.8661 - val_loss: -0.0862\n",
            "Epoch 16/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 282ms/step - accuracy: 0.8352 - loss: -0.1043 - val_accuracy: 0.8577 - val_loss: -0.7357\n",
            "Epoch 17/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 283ms/step - accuracy: 0.8458 - loss: -0.3852 - val_accuracy: 0.8598 - val_loss: 0.1864\n",
            "Epoch 18/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 282ms/step - accuracy: 0.8105 - loss: -0.3126 - val_accuracy: 0.8013 - val_loss: -1.2668\n",
            "Epoch 19/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 283ms/step - accuracy: 0.8177 - loss: -0.3779 - val_accuracy: 0.8452 - val_loss: 0.2325\n",
            "Epoch 20/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 285ms/step - accuracy: 0.8146 - loss: 0.0387 - val_accuracy: 0.8494 - val_loss: -1.1073\n",
            "Epoch 21/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 284ms/step - accuracy: 0.8358 - loss: -0.6482 - val_accuracy: 0.7678 - val_loss: -1.4538\n",
            "Epoch 22/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 282ms/step - accuracy: 0.7811 - loss: -0.3349 - val_accuracy: 0.8640 - val_loss: -0.3117\n",
            "Epoch 23/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 284ms/step - accuracy: 0.8511 - loss: -0.6444 - val_accuracy: 0.8724 - val_loss: -1.3944\n",
            "Epoch 24/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 283ms/step - accuracy: 0.8371 - loss: -0.7889 - val_accuracy: 0.8682 - val_loss: -1.1082\n",
            "Epoch 25/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 285ms/step - accuracy: 0.8441 - loss: -0.5753 - val_accuracy: 0.8682 - val_loss: -0.5865\n",
            "Epoch 26/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 284ms/step - accuracy: 0.8437 - loss: -0.6880 - val_accuracy: 0.8410 - val_loss: -1.9659\n",
            "Epoch 27/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 285ms/step - accuracy: 0.8439 - loss: -0.7118 - val_accuracy: 0.7971 - val_loss: -1.6776\n",
            "Epoch 28/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 284ms/step - accuracy: 0.8408 - loss: -1.1116 - val_accuracy: 0.8724 - val_loss: -1.8916\n",
            "Epoch 29/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 284ms/step - accuracy: 0.8512 - loss: -1.3190 - val_accuracy: 0.8619 - val_loss: -2.6513\n",
            "Epoch 30/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 284ms/step - accuracy: 0.8093 - loss: -0.7707 - val_accuracy: 0.7301 - val_loss: 0.2824\n",
            "Epoch 31/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 283ms/step - accuracy: 0.7667 - loss: 0.3463 - val_accuracy: 0.7699 - val_loss: 0.2400\n",
            "Epoch 32/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 285ms/step - accuracy: 0.7813 - loss: 0.3071 - val_accuracy: 0.7971 - val_loss: 0.1834\n",
            "Epoch 33/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 284ms/step - accuracy: 0.7965 - loss: 0.2306 - val_accuracy: 0.8096 - val_loss: 0.0810\n",
            "Epoch 34/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 283ms/step - accuracy: 0.8173 - loss: 0.1311 - val_accuracy: 0.8410 - val_loss: -0.0375\n",
            "Epoch 35/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 282ms/step - accuracy: 0.8257 - loss: 0.0414 - val_accuracy: 0.7971 - val_loss: -0.3661\n",
            "Epoch 36/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 284ms/step - accuracy: 0.8163 - loss: -0.0767 - val_accuracy: 0.8556 - val_loss: -0.3279\n",
            "Epoch 37/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 284ms/step - accuracy: 0.8242 - loss: -0.0725 - val_accuracy: 0.8619 - val_loss: -0.6119\n",
            "Epoch 38/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 285ms/step - accuracy: 0.8289 - loss: -0.2238 - val_accuracy: 0.8473 - val_loss: -0.7939\n",
            "Epoch 39/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 282ms/step - accuracy: 0.8281 - loss: -0.2748 - val_accuracy: 0.8640 - val_loss: -0.0864\n",
            "Epoch 40/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 284ms/step - accuracy: 0.8266 - loss: 0.1230 - val_accuracy: 0.8285 - val_loss: -1.1570\n",
            "Epoch 41/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 283ms/step - accuracy: 0.8269 - loss: -0.4332 - val_accuracy: 0.8473 - val_loss: -0.9665\n",
            "Epoch 42/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 282ms/step - accuracy: 0.8339 - loss: -0.7128 - val_accuracy: 0.8243 - val_loss: -1.2769\n",
            "Epoch 43/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 285ms/step - accuracy: 0.8086 - loss: -1.5042 - val_accuracy: 0.8661 - val_loss: -0.6288\n",
            "Epoch 44/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 284ms/step - accuracy: 0.8228 - loss: -0.6290 - val_accuracy: 0.8222 - val_loss: -2.4839\n",
            "Epoch 45/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 285ms/step - accuracy: 0.8196 - loss: -1.8777 - val_accuracy: 0.8598 - val_loss: -1.8014\n",
            "Epoch 46/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 284ms/step - accuracy: 0.7983 - loss: -0.8447 - val_accuracy: 0.8117 - val_loss: 0.1383\n",
            "Epoch 47/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 285ms/step - accuracy: 0.8142 - loss: 0.1346 - val_accuracy: 0.8389 - val_loss: -0.3114\n",
            "Epoch 48/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 285ms/step - accuracy: 0.7890 - loss: 0.0033 - val_accuracy: 0.7406 - val_loss: 0.3325\n",
            "Epoch 49/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 284ms/step - accuracy: 0.7694 - loss: 0.3794 - val_accuracy: 0.7824 - val_loss: 0.2857\n",
            "Epoch 50/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 285ms/step - accuracy: 0.7793 - loss: 0.3191 - val_accuracy: 0.7762 - val_loss: 0.2476\n",
            "Making predictions...\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8209205020920503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3288849877.py:150: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"timestamp\": datetime.utcnow().isoformat(),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network training completed successfully\n",
            "    Accuracy: 0.8209205020920503\n",
            "Setting up GitHub authentication...\n",
            "Enter your GitHub Personal Access Token: ··········\n",
            "GitHub authentication configured successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3288849877.py:135: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  timestamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint push failed: Command '['git', 'commit', '-m', 'Checkpoint 20250923_001626 - bl_nn_01 run 1/5']' returned non-zero exit status 128.\n",
            "  Running seed 43 (2/5)...\n",
            "Original train labels: {'smishing', 'ham', 'spam'}\n",
            "Original test labels: {'smishing', 'ham', 'spam'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3288849877.py:221: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  run_meta = {\"baseline\": baseline_id, \"seed\": seed, \"timestamp\": datetime.utcnow().isoformat()}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model...\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 288ms/step - accuracy: 0.7523 - loss: 0.5512 - val_accuracy: 0.7992 - val_loss: 0.4294\n",
            "Epoch 2/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 280ms/step - accuracy: 0.7365 - loss: 0.4146 - val_accuracy: 0.7406 - val_loss: 0.4059\n",
            "Epoch 3/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 282ms/step - accuracy: 0.7314 - loss: 0.3977 - val_accuracy: 0.7803 - val_loss: 0.3910\n",
            "Epoch 4/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 282ms/step - accuracy: 0.7506 - loss: 0.3795 - val_accuracy: 0.7678 - val_loss: 0.3788\n",
            "Epoch 5/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 282ms/step - accuracy: 0.7663 - loss: 0.3611 - val_accuracy: 0.8159 - val_loss: 0.3378\n",
            "Epoch 6/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 281ms/step - accuracy: 0.7753 - loss: 0.3289 - val_accuracy: 0.7866 - val_loss: 0.2316\n",
            "Epoch 7/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 282ms/step - accuracy: 0.8021 - loss: 0.2537 - val_accuracy: 0.8243 - val_loss: 0.0920\n",
            "Epoch 8/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 281ms/step - accuracy: 0.8113 - loss: 0.1914 - val_accuracy: 0.8745 - val_loss: 0.0893\n",
            "Epoch 9/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 282ms/step - accuracy: 0.8370 - loss: 0.1179 - val_accuracy: 0.8389 - val_loss: -0.0682\n",
            "Epoch 10/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 282ms/step - accuracy: 0.8465 - loss: -0.0173 - val_accuracy: 0.7552 - val_loss: -0.2625\n",
            "Epoch 11/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 282ms/step - accuracy: 0.8080 - loss: 0.1671 - val_accuracy: 0.8264 - val_loss: 0.6184\n",
            "Epoch 12/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 283ms/step - accuracy: 0.8084 - loss: 0.2643 - val_accuracy: 0.8640 - val_loss: -0.2079\n",
            "Epoch 13/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 283ms/step - accuracy: 0.8252 - loss: -0.0831 - val_accuracy: 0.8431 - val_loss: -0.4977\n",
            "Epoch 14/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 284ms/step - accuracy: 0.8365 - loss: -0.0680 - val_accuracy: 0.8577 - val_loss: -0.4990\n",
            "Epoch 15/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 280ms/step - accuracy: 0.8251 - loss: -0.0908 - val_accuracy: 0.8536 - val_loss: 0.2992\n",
            "Epoch 16/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 282ms/step - accuracy: 0.8041 - loss: 0.0244 - val_accuracy: 0.7782 - val_loss: -0.6486\n",
            "Epoch 17/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 284ms/step - accuracy: 0.8196 - loss: -0.2625 - val_accuracy: 0.8243 - val_loss: 1.0055\n",
            "Epoch 18/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 289ms/step - accuracy: 0.7762 - loss: 0.3838 - val_accuracy: 0.7510 - val_loss: -0.1128\n",
            "Epoch 19/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 285ms/step - accuracy: 0.8028 - loss: -0.1969 - val_accuracy: 0.8598 - val_loss: -0.4597\n",
            "Epoch 20/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 283ms/step - accuracy: 0.8128 - loss: -0.2620 - val_accuracy: 0.7971 - val_loss: -0.9441\n",
            "Epoch 21/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 285ms/step - accuracy: 0.8022 - loss: -0.2179 - val_accuracy: 0.8054 - val_loss: -1.0601\n",
            "Epoch 22/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 291ms/step - accuracy: 0.8316 - loss: -0.4150 - val_accuracy: 0.7259 - val_loss: -0.5425\n",
            "Epoch 23/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 293ms/step - accuracy: 0.8136 - loss: -0.6998 - val_accuracy: 0.8640 - val_loss: -1.0984\n",
            "Epoch 24/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 287ms/step - accuracy: 0.8278 - loss: -0.6872 - val_accuracy: 0.8661 - val_loss: 0.2781\n",
            "Epoch 25/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 287ms/step - accuracy: 0.8024 - loss: -0.2342 - val_accuracy: 0.8096 - val_loss: -1.6821\n",
            "Epoch 26/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 288ms/step - accuracy: 0.8230 - loss: -0.2434 - val_accuracy: 0.8640 - val_loss: -1.2810\n",
            "Epoch 27/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 284ms/step - accuracy: 0.8265 - loss: -0.6525 - val_accuracy: 0.8661 - val_loss: -0.6263\n",
            "Epoch 28/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 283ms/step - accuracy: 0.8162 - loss: -0.0595 - val_accuracy: 0.7699 - val_loss: 0.1859\n",
            "Epoch 29/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 284ms/step - accuracy: 0.8039 - loss: 0.2112 - val_accuracy: 0.8117 - val_loss: -0.0767\n",
            "Epoch 30/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 283ms/step - accuracy: 0.7986 - loss: -0.3547 - val_accuracy: 0.8598 - val_loss: -0.5004\n",
            "Epoch 31/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 282ms/step - accuracy: 0.8231 - loss: -0.8993 - val_accuracy: 0.8368 - val_loss: -2.0312\n",
            "Epoch 32/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 282ms/step - accuracy: 0.8124 - loss: -0.6101 - val_accuracy: 0.7657 - val_loss: -0.9749\n",
            "Epoch 33/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 282ms/step - accuracy: 0.8033 - loss: -1.2285 - val_accuracy: 0.8577 - val_loss: -2.1289\n",
            "Epoch 34/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 281ms/step - accuracy: 0.8030 - loss: -0.3151 - val_accuracy: 0.8305 - val_loss: 0.3380\n",
            "Epoch 35/50\n",
            "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 284ms/step - accuracy: 0.7745 - loss: 0.4136 - val_accuracy: 0.7699 - val_loss: 0.2570\n",
            "Epoch 36/50\n",
            "\u001b[1m 63/135\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 277ms/step - accuracy: 0.7686 - loss: 0.3499"
          ]
        }
      ]
    }
  ]
}